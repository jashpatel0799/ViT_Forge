# Experiment metadata
exp_name: vit_curriculum
model_num: 1
details: "Curriculum learning across 6 datasets, final eval on STL10"
seed: 64
optimizer_name: adamw

# Dataset & training
dataset_root: "./data"
dataset_name: "cifar10"   # not used directly, curriculum overrides
input_image_size: 64
input_channel: 3
batch_size: 64
num_epoch: 70             # total not used directly, stages define their own
learning_rate: 0.0006
weight_decay: 0.03

# Model
patch_size: 16
num_head: 8
vit_depth: 12
num_class: 100             # fixed head for curriculum learning
pos_emb_type: "linear" # linear sinusoidal rope

# Logging & saving
wandb_project: "vit-small-data"
wandb_runname: ""
output_dir: "./checkpoints"

# Curriculum sequence
curriculum:
  - { name: mnist,        epochs: 15 }
  - { name: fashionmnist, epochs: 11 }
  - { name: emnist,       epochs: 11 }
  - { name: svhn,         epochs: 11 }
  - { name: cifar10,      epochs: 11 }
  - { name: cifar100,     epochs: 11 }




# exp_name: "pose_emb_script"
# model_num: 1
# optimizer_name: "sgd" # sgd ot adam
# details: "model with  pose emned linear"
# dataset_name: "cifar10"
# seed: 64
# num_epoch: 2
# learning_rate: 1e-3
# input_channel: 3
# input_image_size: 128
# patch_size: 16
# # embedding_size: 768
# num_head: 8
# vit_depth: 12
# batch_size: 64
# num_class: 10
# pos_emb_type: "linear" #linear sinusoidal rope
# wandb_project: "vit-small-data"
# output_dir: "results"